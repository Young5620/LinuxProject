## 빅데이터 분석
 : 탐색과 분석을 반복하며 의미있는 데이터를 추출해 문제를 검증하고 주요 의사결정을 내리는 과정

 - 기술 분석: 분석 초기 데이터의 특징을 파악하기 위해 선택, 집계, 요약 등 양적 기술 분석을 수행
 - 탐색 분석: 업무 도메인 지식을 기반으로 대규모 데이터셋의 상관관계나 연관성을 파악
 - 추론 분석: 전통적인 통계분석 기법으로 문제에 대한 가설을 세우고 샘플링을 통해 가설을 검증
 - 인과 분석: 문제 해결을 위한 원인과 결과 변수를 도출하고 변수의 영향도를 분석
 - 예측 분석: 대규모 과거 데이터를 학습해 예측 모형을 만들고, 최근의 데이터로 미래를 예측

## 빅데이터 분석에 활용 기술

1. 임팔라 :  인메모리 기반의 실시간 온라인 분석으로까지 확대
  임팔라의 아키텍처는 하둡의 분산 노드에서 대규모 실시간 분석을 위해 Impalad, Statestored, Catalogd라는 컴포넌트가 설치
   Impalad는 HDFS의 분산 노드 상에서 실행 계획과 질의 작업을 수행하는 데몬이고
   Statestored는 Impalad의 기본 메타 정보부터 각 분산 노드에 설치돼 있는 Impalad를 관리하는 역할
   Catalogd는 Impalad와 Statestored와 통신하면서 임팔라 SQL의 실행과 변경 이력을 관리

2. 제플린 : 'R'프로그램의 경우 분산 파일을 직접 참조할 수 없고 분산 병렬처리가 어려워 하둡의 대규모 데이터를 분석하는 데 어려움
              이를 해결하고자 스파크를 기반으로 하는 제플린이 탄생
  제플린의 아키텍처는 웹 UI의 NoteBook에서 스파크 또는 스파크 SQL을 작성해 하둡 클러스터에 작업을 요청하고, 
  처리 결과를 다시 웹 UI에서 시각화해서 볼 수 있다. 이때 제플린의 클라이언트와 서버 사이에 REST 또는 웹소켓 통신을 요청하게 되며, 
  요청된 결과에 해당하는 인터프리터가 작동해서 타깃 시스템에 작업을 요청하게 된다. 제플린은 스파크뿐 아니라 
  다양한 확장 인터프리터(스파크, 하이브, 플링크(Flink), R, 카산드라 등)를 제공한다.

3. 머하웃 : 하둡 생태계에서 머신러닝 기법을 이용해 데이터 마이닝을 수행하는 툴
  머하웃은 하둡의 분산 환경 위에 맵리듀스를 기반으로 고급 분석을 지원하는 라이브러리 패키지다. 
  하둡 클러스터 관점에서 보면 머하웃의 머신러닝 알고리즘이 맵리듀스에서 작동하도록 구현됐기 때문에 
  선형 확장으로 대규모(테라급 이상) 머신러닝 작업이 가능한 아키텍처를 가지고 있다. 주요 관련 라이브러리로는 추천, 분류, 군집이 있다.

4. 스쿱 :  RDBMS와 HDFS 사이에서 데이터를 편리하게 임포트하거나 익스포트해주는 소프트웨어가 스쿱(Sqoop)이다.
  스쿱 1 아키텍처는 스쿱의 CLI로 임포트, 익스포트 명령을 하둡에 전달하면 맵 태스크가 병렬로 실행되어 외부 데이터베이스와 HDFS 사이에서 
  대량의 데이터를 임포트 및 익스포트할 수 있는 아키텍처를 제공한다.
  스쿱 2 아키텍처의 특징은 스쿱 1의 아키텍처를 확장해서 스쿱 서버를 추가한 것이다.
  스쿱 1에서 클라이언트마다 설치됐던 커넥터와 라이브러리를 스쿱 서버에 배치하고 스쿱의 임포트, 익스포트 기능을 REST API로 제공해서 클라이언트를 경량화했다. 
  이처럼 스쿱의 주요 기능을 중앙 집중화함으로써 잡을 통합 관리하고 스쿱 1에서 할 수 없었던 접근 통제가 가능해졌다.


## 실습

임팔라 -> 제플린 -> 머하웃 -> 스쿱 설치

1) Hive QL과 임팔라의 속도차이 : 임팔라가 훨씬 빠르다!
2) %sh
hdfs dfs -cat /user/hive/warehouse/managed_smartcar_drive_info/biz_date=20220428/* |head
** -cat : 파일 실행
   -ls : 디렉토리 아래에 있는 파일보여주기
** 제플린은 스파크를 실행시켜주는 프로그램이다
java.class.cast.Exception 시 -> zeppelin restart
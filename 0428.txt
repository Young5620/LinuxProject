## 데이터 생성
로그 시뮬레이터를 이용해 오늘 날짜의 “스마트카 상태 정보 데이터를 생성
날짜: 2022년 4월 28일이었고 5대의 스마트카를 지정

저사양 파일럿 환경: 플럼 서비스를 시작한다.
플럼 서비스: CM 홈 → [Flume] - [시작]
$ cd /home/pilot-pjt/working
$ java -cp bigdata. smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20220428 5 &

파일이 100MB 파일 크기로 생성된 것을 확인한 후, 로그 시뮬레이터를 종료한다.
$ cd /home/pilot-pjt/working/SmartCar/
$ ls -ltrh SmartCarStatus Info_20200322.txt
$ ps -ef | grep smartcar.log
$ kill -9 [pid]

## 데이터 적재
스마트카 상태 정보 데이터를 플럼의 수집 디렉터리로 옮긴다. 플럼이 수집 작업을 시작한다.
$ mv /home/pilot-pjt/working/SmartCar/SmartCarStatus Info_20200322. txt /home/pilot-pjt/working/car-batch-log/

## 데이터 적재 확인
오늘 날짜의 스마트카 상태 정보가 HDFS에 정상적으로 적재됐는지 확인한다.
$ hdfs dfs -ls -R /pilot-pit/collect/car-batch-log/
wrk_date=20220428 확인
디렉터리 아래에 .tmp인 파일이 있으면 아직 플럼에서 적재 중이니 완료될 때까지 기다린다.

## 운전자 운행로그 생성
플럼, 카프카, 스톰, 레디스, Hbase 서버가 정상 상태인지 먼저 확인하도록 한다. 
특히 스톰의 경우 자동 스타트가 안 되는 경우가 많으니 스톰의 Ninbus와 Supervisor의 기동 상태를 꼭 확인해 본다.
플럼 서비스: CM 홈 → [Flume] - [시작]
카프카 서비스: CM 홈 → [Kalka] → [시작]
스톰 서비스: Server02에 SSH로 접속해 다음 명령을 실행
$ service storm-nimbus start
$ service storm-supervisor start
$ service storm-ui start
레디스 서비스: Server02에 SSH로 접속해 다음 명령을 실행
$ service redis_6379 start
HBase 서비스: CM 홈 → [HBase] → [시작]

저사양 파일럿 환경: 스마트카 대수를 10 이하로 조정한다.
저사양 환경에서 스마트카 100대로 시뮬레이션 하면, 서버에서 병목 현상과 타임아웃 등의 문제가 발생할 수 있다. 
이를위해 스마트카 대수 옵션을 10 이하로 설정한다.

$ cd /home/pilot-pjt/working
$ java cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar. loggen. DriverLogMain 20200322 100 &

스마트카 운전자의 운행 로그 확인
실시간 운행 로그 데이터가 정상적으로 생성됐는지 확인
/home/pilot-pjt/working/driver-realtime-log/에 SmartCarDriverInfo.log 파일이 생성됐을 것이다. 
로그는 24시간을 기준으로 지속적으로 생성된다. tail 명령으로 실시간 로그가 계속 기록되는지 확인해 보자.
$ cd /home/pilot-pjt/working/driver-realtime-log
$ tail -f SmartCarDriverInfo.log


## 스마트카 운전자의 운행 데이터 적재 확인
오늘 날짜의 모든 운행 데이터가 HBase에 정상적으로 적재됐는지 휴를 통해 확인해 보자.

휴에 접속해 [좌측 메뉴 펼치기] -- [LIBase] - [DriverCarInfo] 테이블을 선택해 실행일자(“20200428")의 운행 데이터가 생성됐는지 확인
HBase 브라우저 검색에 실행 일자를 역변환한 로우키의 prefix “00000022300202"를 입력하면 등록된 로우키 목록이 자동 완성되어 나타난다. 
이 가운데 아무 로우키나 선택하고 뒤에 콤마(",")를 입력하고 [검색] 버튼을 클릭하면 해당 로우키 스마트카 운전자의 실시간 운행 정보가 HBase에서 조회된다.

레디스 CLI를 실행해 오늘 날짜로 과속한 스마트카 차량 정보를 확인
로그 시뮬레이터 상황에 따라 아직 과속 차량이 발생하지 않았을 수도 있다.
$ redis-cli
$ 127.0.0.1: 6379) smembers 20200322
과속 차량이 3대 이상 발견되면 스마트카 운전자에 대한 운행 로그 시뮬레이터도 종료시킨다. 
앞서 실행했던 스마트카 상태 정보 로그 시뮬레이터도 강제로 종료한다.
$ ps -ef | grep smartcar.log
$ kill -9 [pid] [pid]

저사양 파일럿 환경: 수집/적재 기능을 정지시킨다.
플럼 서비스: CM 홈 → [Flume] → [정지]
- 카프카 서비스: CM 홈 → [Kafka] → [정지]
스톰 서비스: Server02에 SSH로 접속한 후 다음 명령을 실행
$ service storm-ui stop
$ service storm-supervisor stop
$ service storm-nimbus stop
레디스 서비스: Server02에 SSH로 접속한 후 다음 명령을 실행
$ service redis_6379 stop
HBase 서비스: CM 홈 → [HBase] → [정지]


## 스마트카 상태 정보 모니터링 워크플로 작성

저사양 파일럿 환경: 우지 서비스를 시작한다.
- 우지 서비스: CM 홈 → [Oozie] → [시작]

작업 디렉터리를 만듬
1 휴의 좌측 드롭박스 메뉴에서 [문서 메뉴를 선택해 내 문서 기능을 실행한다.
하이브 스크립트 파일을 저장하기 위한 작업 폴더를 workflow"라는 이름으로 생성한다.
workflow - hive_script - subject1 디렉토리 생성
subject1 
subject2 
subject3 
subject4 
subject5 
그림 6.66 주제 영역에 사용할 디렉터리 생성
02. 주제 영역 1에서 사용할 하이브 스크립트 파일 3개를 만든다. 먼저 내 문서에서 /workflow/hive_script/subject
위치로 이동한다. [새 문서 → [Hive 쿼리를 선택한다.
내 문서 > workflow hive_script subject1 모두
현재 폴더가 비어 있습니다. 오른쪽 상단의 메뉴에서 새 파일 또는 돈더를 추가
Q1
Hive 121
C Plg 스크립트
그림 6.67 주제 영역 1에 사용할 하이브 파일 생성
Workflow
2
Bundle
03. 하이브 쿼리를 작성할 수 있는 에디터가 그림 6.68처럼 활성화된다.
Hive Add a name... Add a description... 1 O
Database default - 유형 lexlr ? X?
1 A: SELECT FROM GOIN' Ctrl + space
그림 6.68 하이브 쿼리 에디터
! A
263
| 실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
04. 하이브 에디트 창에 그림 6.69처럼 "Create Table.." DDL 문장을 입력하고 상단의 [저장] 버튼을 클릭한다. 파일
명 입력창이 나타나면 파일명을 "create_table_managed_smartcar_status_info.hal"로 입력하고 [Save] 버튼
을 클릭한다. 하이브 QL은 C://예제소스/bigdata2nd-master/CH06/HiveQL/그림 6.69.hql로 제공되므로 참고
한다.
Hive Add a name... Add a description...
1 create table if not exists Managed_SmartCar_Status_Info (
2 car_number string,
3 sex string,
4 age string,
5 marriage string,
6 region string,
7 job string,
8 car_capacity string,
9 car year string,
10 car_model string,
11 tire_fl string,
12 tire_fr string,
13 tire_bl string,
14 | tire_br string,
15 light_fl string,
16 light_fr string,
17| light_bl string,
18| light_br string,
19 engine string,
20 break string,
21| battery string,
22| reg_date string
23
24| partitioned by ( biz_date string )
25 | row format delimited
26 | fields terminated by ','
27 stored as textfile;
그림 6.69 주제 영역 1에 사용할 하이브 테이블 쿼리 작성
그림 6.69의 하이브 CREATE TABLE 문은 하이브의 Managed 영역에 주제 영역 1에 대한 Mamaged_
Smartcar_Status_Info라는 테이블을 만든다. 첫 줄에 if not exists"라는 절을 이용해 테이블이 없으면 만들
고 이미 있으면 무시하게 한다. 칼럼을 보면 기존 External 영역에서 만든 SmartCar Status_Info 테이블 칼럼과
SmartCar_Master 테이블의 칼럼이 합쳐져 있는 것을 확인할 수 있다.
05. 계속해서 내 문서 /workflow/hive_script/subjecti의 위치에 두 번째 하이브 스크립트 파일을 만들어 본다.
subject1 디렉터리에서 [새 문서 → [Hive 쿼리를 선택한다.
06. 하이브 에디트 창에 External의 SmartCar_Status_Info 테이블에 작업 일자(오늘 날짜를 기준으로 파티션 정보
를 추가하는 스크립트를 작성한 후 저장한다. 파일 이름 입력창이 나타나면 이름을 "alter_partition_smartcar_
status_info.hgl"로 입력하고 [Save] 버튼을 클릭한다.
Hive
!
Add a name... Add a description...
1| alter table SmartCar_Status_Info add if not exists partition(wrk_date='${working day}');
그림 6.70 주제 영역 1에 사용할 파티션 생성
1
264
06. 비데이터 탐색
그림 6.70의 ALTER 쿼리를 보면 SmartCar_Slatus_Info 테이블에 wrk_date(작업일 또는 수집일) 필드를 기준으
로 동적 파티션(${working_day})이 사용되는데, 해당 값은 우지 예약 작업의 매개변수인 "today"에 할당된 값
으로부터 가져올 것이다. Today 매개변수에 대한 설명은 다음의 예약 작업 설정 단계에서 설명한다.
07. 내 문서의 workflow/hive_script/subject1 위치에 세 번째 하이브 스크립트 파일을 만든다. [새 문서] → [Hive 쿼
리를 선택한다.
08. 하이브 에디트 창이 활성화되면 먼저 동적 파티션을 생성하기 위한 하이브 환경변수 값을 설정해야 한다. 동적 파
티션은 지정된 특정 필드값을 기준으로 자동 파티션되는 기능인데, 다음의 옵션을 반드시 지정해야 한다.
. set hive.exec.dynamic.partition = true;
- set hive.exec.dynamic.partition.mode = nonstrict;
동적 파티션 설정에 이어서 External 영역에 생성돼 있는 두 테이블인 SmartCar_Master_Over18과 SmartCar_
Status_Info를 조인해서 조회된 데이터를 앞서 만든 Managed 테이블인 Managed_SmartCar_Status_Info에
삽입하는 하이브 스크립트를 작성하고 [저장] 버튼을 클릭한다. 파일명은 "insert_table_managed_smartcar_
status_info.hgl”로 지정한다.
Hive D Add a name... Add a description...
1 set hive.exec.dynamic.partition=true;
2 set hive.exec.dynamic.partition. mode=nonstrict;
3
4 insert overwrite table Managed_SmartCar_Status_Info partition (biz_date)
5| select
6 t1.car_number,
7 t1.sex,
8 t1.age,
9 t1.marriage,
10 t1.region,
11 t1.job,
12 t1.car_capacity,
13 t1.car year,
14 t1.car_model,
15 t2.tire_fl,
16 t2.tire_fr,
17 t2.tire_bl,
18 t2.tire_br,
19 t2.light_fl,
20 t2.light_fr,
21 t2.light_bl,
22] t2.light_br,
23 t2.engine,
24 t2.break,
25 t2.battery,
26 t2.reg_date,
27 substring(t2.reg_date, 0, 8) as biz_date
28 from SmartCar_Master_Over 18 t1 join SmartCar_Status_Info t2
29 | on t1.car_number = t2.car_number and t2.wrk_date = '${working_day}';
MARA
그림 6.71 주제 영역 1의 Managed 테이블에 데이터를 생성하는 쿼리 작성
그림 6.7의 하이브 쿼리에서 SmartCar_Master_Over18 테이블은 6.5장에서 스파크-SQL로 조회했던 결과를 제
장한 테이블이다.
265
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
-
09. 상단의 쿼리 콤보박스에서 [스케줄러] → [Workillow]를 선택해서 실행할 워크플로를 만든다(좌측 드롭박스 메뉴의
[스케줄러를 선택해도 된다).
= (ce 퀴리 Q Search saved documents
편집기 + 그저
이 스케줄러 3 Workflow 3
클러스터
1 HBese 파인이 김 이 예약
Bundle
훔 | pilot-pjt / workflow / hive_script / subject1
이 름
1
alter_partition_smartcar_status_info.hal
그림 6.72 휴의 워크플로 생성
10. 첫 번째 작업으로 주제 영역 1의 데이터를 관리하기 위해 Managed 영역에 하이브 테이블을 만드는 작업을 추가
한다. 워크플로의 작업 툴 박스에서 “Hive 쿼리(HiveServer2 스크립트) 작업을 워크플로의 첫 번째 작업 노드
에 드래그 앤드 드롭한다.
Ol Oozie 편집기 미저장
문서 ~ >
My Workflow
Add a description...
여과 두기
A
그림 6.73 Hive 쿼리 작업 생성
.
266
11. 사용할 Hive 쿼리 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 tigurester" 한
들어 놓은 create_table_managed_smartcar_statis_info.hal을 선택한 후 [추가] 버튼을 누른다.
? Hive
Hive query
스가
insert_table_managed_smartcar_status_info.hal
alter partition_smartcar_status_info.hal
create_table_managed_smartcar_status_info.hal
그림 6.74 Hive 쿼리 작업 파일 선택
12. 두 번째 작업으로 데이터를 가져올 External 영역의 SmartCar_Status_Info 테이블에 오늘 날까로 파티션 정보를
설정하는 하이브 작업을 만든다. 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 두 번째 작업 노드에
드래그 앤드 드롭한다.
문서 ~ Q
My Workflow
Add a description...
Hive
create_table_managed_smartcar_status_i
매개변수 + 파일 +
그림 6.75 Hive 쿼리 작업 생성
13. 사용할 Hive 쿼리 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 workflow/hive_script/subject1에 만
들어 놓은 alter_partition_smartcar_status_info.hql을 선택한 후, [추가] 버튼을 클릭한다.
267
| 실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
? Hive
Hive query 문서 검사....
Inserttable_managed_smartcar_status_info.hal
alter partition_smartcar_status_info.hal
create_table_managed_smartcar_status_info.hal
그림 6.76 Hive 쿼리 작업 파일 선택
14. 그림 6.71 의 하이브 스크립트 안에서 정의한 작업일자(수집일자) 매개변수인 ${working_day}의 값을 그림 6.77의
워크플로 매개변수와 연결한다. 이때 working_day 매개변수에 ${today를 설정하는데, 이 값은 잠시 후 우지의
예약 스케줄러에서 정의해 등록한다.
• working_day=${today }
Hive X
create_table_managed_smartcar_status_info.hral
매개변수 + 파일 +
Hive X ----
alter_partition_smartcar_status_info.hal
1 매개변수+ 파일 +
workingday=${today
그림 6.77 Hive 쿼리 작업의 매개변수 설정
working_day의 값으로는 워크플로가 실행되는 시점에 YYYYMMDD 형식의 날짜값이 들어올 것이다. 만약 임의
의 값을 강제로 설정하고 싶다면 working_day-20200301" 처럼 “20200301"을 직접 입력하면 된다.
268
06 빅데이터 탐색
15. 마지막 작업으로 첫 번째 작업에서 만든 Managed_SmartCar_Status_Info 테이블에 데이터를 저장하기 위한 하
이브 작업을 만든다. 워크플로의 작업 툴박스에서 "Hive 쿼리 작업을 워크플로의 네 번째 작업 노드에 드래그 앤
드 드롭한다.
시. DO >_
My Workflow
Add a description...
Hive
create_table_managed_smartcar_status_info.in
매개변수 + 파일 +
+ 1.2 Hive
alter-partition_smartcar_status_info.hal
매개변수 + 파일 +
working day=${
그림 6.78 Hive 쿼리 작업 생성
16. 사용할 Hive 쿼리 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 /workflow/hive_script/subjecti에 있
는 insert _table_managed_smartcar_status_info.hg을 선택한 후, [추가] 버튼을 클릭한다.
432 Hive x
Hive query | 문서 검색...
insert_table_managed_smartcar_status_info.hal
주가 alter_partitlon_smartcar_status_info.hql
create_table_managed_smartcar_status_info.hal
그림 6.79 Hive 쿼리 작업 파일 선택
269
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
17. 이번에도 하이브 스크립트 안에서 정의한 작업일자(수집일자) 매개변수인 $(working_day}의 값을 워크플로의
매개변수와 연결한다. working_day 매개변수에 $(today}를 설정하는데 이 값은 잠시 후 우지의 예약 작업의
Scheduler 설정 단계에서 정의한다.
- Working_day = ${today}
Hive X
기
insert_table_managed_smartcar_status_info.hal
I 매개변수 + 파일 +
② | working_day=$(today
그림 6.80 Hive 쿼리 작업의 매개변수 설정
18. 워크플로의 이름을 지정한다. 워크플로 상단의 "My Workflow"를 클릭하고, "Subject 1 - Workflow"로 변경한 후
[확인] 버튼을 클릭한다.
문서
O My Workflow
Add a description....
Subject 1 - Workflow
+? Hive
그림 6.81 주제 영역 1의 워크플로 이름 설정
19. 워크플로 작성을 완료한다. 우측 상단의 [저장] 버튼을 누른다.
O Oozie 편집기 미저장
문서 16 0 >
그림 6.82 주제 영역 1 워크플로 저장 및 완료
x
270
20. 이제 작성한 워크플로를 작동하기 위한 예약 작업을 생성한다. 그림 6.23 처럼 상단의 쿼리 콩보박스에서 스카줄
레 → [예약을 선택한다.
= Ue 리 a Secrets
지기
고 스케줄러 Worrow
C/ 예약 3
Eace
workfow
subject 2 -Workfiow
see 약
Soject 1 - Workflow
그림 6.83 휴의 예약 작업 생성
21. 예약 작업의 이름을 "Subject 1 - 예약'으로 입력한다.
O Oozie 편집기
O My Schedule Casect -
ACT 2 9
x
예정된 Workflow는 무엇입니까?
Subject 1 - Worlcow
그림 6.84 주제 영역 1의 예약 이름 지정
2. 예약 작업에서 사용할 워크플로를 선택한다. 앞서 만든 주제 영역 1의 워크플로인 'Subject 1 - Workflow'를 선택
한다.
Workfow 선력
OC Oozie 편집기
Subject 1 -019 Worktion Subject 1 -Wone
Add a description
예정된 Workflow는 무엇입니까?
wection 선택 | 1
그림 6.85 주제 영역 1의 예약 작업에서 작동시킬 워크플로 선택
271
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
23. 예약 작업의 워크플로를 주기적으로 실행하기 위한 일종의 배치 잡 스케줄러다. 그림 6.86처럼 스케줄러 실행 주
기와 옵션 값을 설정한다. 시작일자와 종료일자는 파일럿 프로젝트 실습일자에 맞춰 입력한다.
간격은 얼마입니까?
다음 미다 일 다음에서 1:0
숨기기
이 고급 구문
시간대 | Asla/Seoul
원본 2020-03-23 00:00
2020-12-31 © 23:59
그림 6.86 주제 영역 1 예약 작업의 작동 스케줄링 설정
그림 6.86의 설정에 대한 워크플로의 스케줄링 내용은 다음과 같다.
실행 간격: 매일, 1시
시작 일자: 2020년 03월 23일, 00시 00분
종료 일자: 2020년 12월 31일, 23시 59분
11ZECH: Asia/Seoul
위 설정은 2020년 03월 23일부터 2020년 12월 31일까지, 매일 새벽 1시에 예약 작업과 연결돼 있는 워크플로가
작동한다. 참고로 이번 파일럿 프로젝트에서 5개의 주제 영역에 대한 예약 작업을 60분 간격으로 등록할 것이다.
.
.
272
06 비대이터 탐색
Tip _ 워크플로 즉시 실행하기
그림 6,86의 설정대로라면 익일 새벽 1시가 돼서야 워크플로의 작동 여부를 확인할 수 있다. 테스트를 위해 워크플
로를 즉시 실행할 수 있는 좀 더 쉬운 방법이 있는데, [내 문서에서 실행할 워크플로를 선택하고 들어가 상단의 [수
정] 버튼을 클릭하고 매개변수의 작업 일자(매개변수: working_day=YYYMMDD)를 그림 6.87처럼 독자의 파일
럿 상황에 맞춰 직접 입력한 후 상단의 [저장] → [제출] 버튼을 차례로 누르면 워크플로가 즉시 실행된다. 매개변수
설정이 필요없는 워크플로는 곧바로 [저장] → [제출을 선택하면 된다.
-
00 oozie 편집기
3
Hive x
create_table_managed_smartcar_status_info.hgl...기
매개변수 + 파일 +
Hive X
alter_partition_smartcar_status_info.hgl 가
매개변수 + 파일 +
working day=202003
1
Hive
one
insert_table_managed_smartcar_status_info.hot...
매개변수 + 파일 +
working day=202003
2
>
그림 6.87 예약 기능 즉시 실행하기 설정 2
24. 워크플로에서 사용할 매개변수인 today 값을 설정한다.
매개변수
working_day
+ 매개변수 추가
매개변수 ~ S{coord:formatTime(coord:dateTzOffset(coord:nominalTime(), "Asia/Seout). YYYYMMdd>
그림 6.88 주제 영역 1 예약 작업의 수행일자 매개변수 설정
273
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
앞서 워크플로의 하이브 작업에서 작업일자(수집일자) 매개변수를 "working_day={(today}"로 등록했다. today
의 값을 예약 작업의 내장 함수를 통해 다음과 같이 설정한다.
${coord: formatTime(coord:dateTzoffset(coord:nominalTime(), "Asia/Seoul"), 'yyyyMMdd')}
25. 우지의 예약 작업 설정이 모두 끝났다. [저장] 버튼을 누르고 작성을 완료한다.
O Oozie 편집기
Subject 1 -- 예약
Add a description
예정된 Workflow는 무엇입니까?
미저장
Subject 1 - Workflow
그림 6.89 주제 영역 1의 예약 기능 저장 및 완료
26. 작성이 완료된 예약 작업을 우측 상단의 [제출] 버튼을 클릭해 실행한다.
O Oozie 편집기 9
Subject 1 - 01/07
Add a description... Subject 1 - 예약을(를) 제출하시겠습니까? X
예정된 Workflow는 start_date
2020-03-23T00:00 Subject 1 - Workflow a
end_date
2020-12-31T23:59
O Job을 제출하기 전에 모의 테스트 진행
2
취소 제출
그림 6.90 주제 영역 1의 예약 기능 제출 및 실행
►
274
6 빅데이터 탐색
27. 제출된 예약 작업 상태를 확인해 본다. 우측 상단의 [Job] 버튼을 클릭하고 잡 브라우저에서 [일정을 선택한다. 암
서 등록한 "Subject 1 - 예약"이 설정한 스케줄러 시간에 따라 "PREP(준비)", "Running(실행)" 상태 등으로 표기
되며, 매일 새벽 1시가 되면 등록된 워크플로가 작동하게 된다.
리 Q Search saved documents .. Job admin
Job Browser Job Workflow 일정 Bundle SLAS
User admin 이미성공 | □ 실패한 11
실행 중
이중 사용자 유형 상대 그 수정됨 소요시간 10
Subject 1 - 예약 admin schedule RUNNING 44 2020449 41 COCCOOG-200322142417077
전 101 0 본
2234,23,
59m, 05 DOOC
그림 6.91 예약 기능 모니터링 1
28. 잡 브라우저에서는 등록된 잡의 현황, 진행 상태, 처리 이력과 결과 등을 확인할 수 있다.
Job Browser Job Workflow 일정 Bundle SLAS
useradmin 이 성공 실행 중 □ 실패함 11
실행 중
이름 사용자 유형 상태 진행 그룸 수정됨 소요시간 ID
U Subject 1-09 admin schedule RUNNING 49 2020년 4월 4일 오 0000000
전 10시 0분
283d, 23h.
59m, Os 200325213569078- code
COZ-C
Completed
이름 사용자 유형 상태 진행률 그룹.. 수정됨 소요시간 ID
Subject 1 - 0494 admin schedule KILLED 4 2020년 4월 4일 오 283d, 22. 2000004 200325213559073
전 10시 0분 59m. Os Nozoo HC
Subject 1 - 예약 admin schedule KILLED 4% 2020년 4월 4일 오 0000001-2003 23023611310
전 10시 0분
2831 221.
59m, Os Coz-z-C
그림 6.92 잡 브라우저 모니터링
특정 워크플로가 실행 중일 때는 그림 6.93처럼 작업 진행 상태를 프로그레스바로 곧바로 확인할 수 있다.
275
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
W Subject 1 - Workflow
ID
0000000-20032302361
1310-00zieroozi-W
그래프 속성 로그 작업 XML
Subject 1 - Workflow i
대
SUCCEEDED 22Hive
사용자
admin
create_table_managed_smartcar_status_int
i
진명
100%
2 Hive
소요 시간
7m, 42s alter_partition_smartcar_status_info.hgli
지출됨
2020년 3월 23일 오전 ..... 2.2 Hive
insert_table_managed_smartcar_status_inf
1
그림 6.93 실행 중인 워크플로 모니터링
예약된 작업들이 활성화되어 실행될 때는 우측 상단에 [Job Browser]의 버튼 우측에 실행 중인 잡의 개수가 표시
된다. [작업 미리보기를 클릭하면 실행 중이거나 종료된 잡의 상세 정보를 확인할 수 있다.
Job| 13 & admin
Job Workflow 일정
user:admin 01 그 성공 그 실행 중 그 실패함
몇 초 전 - ACCEPTED
Oozie Launcher
oozie:launcher:T=hive2:W=Subject 1 - Wor...
3.70s
admin
application_1585139700601_0006
16 분 전 - KILLED
Oozie Launcher
oozie:launcher.Təhive2:W=Subject 1 - Wor...
7.84s
& admin
application_1585139700601_0005
17 분 전 - SUCCEEDED
Oozie Launcher
oozie:launcher:T=hive2:W=Subject 1 - Wor...
27.985
& admin
application_1585139700601_0004
20 분 전 - SUCCEEDED
Oozie Launcher
oozie:launcher:T=hive2:W=Subject 1 - Wor...
19.35
& admin
application_1585139700601_0003
그림 6.94 작업 미리 보기
276
06 빅데이터 탐색
29. "Subject 1 - Workflow"가 정상적으로 작동했으면, 휴의 Hive Editor로 이동해서 그림 6.95와 같이 하이브 OL을
작성해서 실행한다. "biz_date=20200322" 의 날짜는 독자들의 파일럿 환경의 실행 일자에 맞춰 입력해야 한다.
참고로 워크플로를 통해 만들어지는 managed_smartcar_status_info 같은 테이블이 하이브 편집기에서 곧바로
표기되지 않아 하이브 편집기에서 해당 테이블 관련 쿼리를 실행할 때 에러가 발생할 수 있다. 이때는 하이브 테이
블 목록 상단의 [새로고침] 버튼을 클릭해 테이블 목록을 새롭게 갱신한다.
1 select * from managed_smartcar_status_info
2 where biz date = '20200322' limit 19
그림 6.95 주제 영역 1 워크플로의 실행 결과 확인 1
실행 결과는 다음과 같다. 가장 우측 열의 biz_date 칼럼에 날짜가 “20200322"인 것을 확인할 수 있다.
쿼리 기록 저장된 쿼리 결과 (10)
tatus_info.battery managed_smartcar_status_info.reg_date managed_smartcar_statu
1 20200322000000 20200322
2 20200322000004 20200322
1 3 20200322000008 20200322
4 20200322000012 20200322
5 20200322000016 20200322
그림 6.96 주제 영역 1 워크플로의 실행 결과 확인 2
30. 한번 등록한 예약 작업은 종료 기간까지 계속 활성화된 상태로 남아 있게 되어 파일럿 환경의 리소스를 차지하게
된다. 파일럿 환경에서는 매일 워크플로가 실행될 필요가 없으니 실행 및 테스트가 끝난 작업은 휴 좌측 드롭박스
메뉴의 [Job] → [일정을 선택해 실행 중인 예약 작업들을 모두 중지시킨다.
주제 영역 2. 스마트카 운전자 운행 기록 정보 워크플로 작성 실습 BBBEN
주제 영역 2부터는 많은 부분이 주제 영역 1과 유사한 작업이 반복되므로 지면상 약식으로 진행한
다. 이번 장의 워크플로 작성이 어렵게 느껴지는 독자의 경우 주제 영역 1을 다시 한번 꼼꼼히 살펴
보기 바란다.
이번 주제 영역 2의 워크플로는 2020년 03월 22일자로 HBase의 테이블에 적재된 “스마트카 운
전자의 운행 데이터를 우지 워크플로를 이용해 하이브의 Managed 영역인 Mart 테이블로 매일 이
동시키는 프로세스다. 기억을 되살려 보면 HBase에 적재된 “스마트카 운전자 운행 데이터”는 하이
-
277
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
브의 HBase 핸들러라는 것을 이용해 하이브의 테이블(SmartCar Drive Info)에 연결해서 하이브
의 조회로 확인이 가능했다. 이를 이용해 “스마트카 운전자 운행 데이터”와 “스마트카 마스터 데이
터"를 조인해서 좀 더 확장된 스마트카 운전자 운행 데이터를 만든다. 워크플로의 하이브 작업에 사
용되는 하이브 QL은 C://예제소스/bigdata2nd-master/CHO6/HiveQL/의 경로에서 제공되므로
필요 시 해당 파일을 열어 참고한다.
저사양 파일럿 환경: HBase 서비스를 시작한다.
• HBase 서비스: CM 홈 → [HBase] → [시작]
01. 휴의 좌측 드롭박스 메뉴에서 [문서를 선택해 [내 문서]에 생성해 놓은 주제 영역 2의 작업 디렉터리로 이동한다.
휴 내 문서: /workflow/hive_script/subject2
02. 주제 영역 2에서는 사용할 하이브 스크립트 파일 4개를 작성한다. 먼저 내 문서의 /workflow/hive_script/
Subject2로 이동해서 우측 상단의 [새 문서] → [Hive 쿼리를 클릭한다.
03. 스마트카 운전자의 운행 기록을 저장하기 위한 CREATE TABLE 스크립트를 작성하고, 상단의 [저장] 버튼을 클릭
해 파일 이름을 "create_table_smartcar_drive_info_2.hqI"로 입력한 후 저장한다.
Hive Add a name... Add a descri... :
Database default 유형 textr ?
1 create external table if not exists SmartCar_Drive_Info_2 (
2 r_key string,
3 r_date string,
4 car_number string,
5 speed_pedal string,
6 break_pedal string,
7 steer_angle string,
8 direct_light string,
9 speed string,
10 area_number string
11)
12 partitioned by wrk_date string )
13 | row format delimited
14 fields terminated by ','
15| stored as textfile
16| location '/pilot-pjt/collect/drive-log/"
그림 6.97 주제 영역 2의 운행 기록을 관리하기 위한 하이브 테이블 생성 쿼리
278
06 빅데이터 탐색
그림 6.97의 SmartCar_Drive_Info_2 테이블은 HBase의 테이블에 연결된 SmartCar Driver_Info 데이터를 하이
브 테이블로 재구성하기 위해 생성한 테이블이다.
04, 계속해서 내 문서의 /workflow/hive_script/subject2에 두 번째 하이브 스크립트 파일을 만들어 본다. subject2
디렉터리에서 [새 문서] → [Hive 쿼리를 클릭한다.
05. 하이브 에디터 창이 활성화되면 Hbase의 테이블에 연결된 SmartCar_Drive_Info 테이블로부터 “2020년 03월
22일에 발생한 운행 데이터를 조회해서 하이브 테이블인 SmartCar_Drive_Info_2에 등록하기 위한 동적 파티션
설정과 쿼리를 작성한다. 상단의 [저장] 버튼을 클릭하고 파일 이름은 "insert_table_smartcar_drive_info_2.hql"
로 입력하고 저장한다.
• set hive.exec.dynamic.partition=true;
- set hive.exec.dynamic.partition.mode=nonstrict;
Hive Add a name... Add a descriptio...
Database default 유형 textr 요?
TILR....M.RRRR..
set hive.exec.dynamic.partition=true;
2 set hive.exec.dynamic.partition.mode=nonstrict;
3
4 insert overwrite table SmartCar Drive_Info_2 partition (wrk_date)
5| select
6 r_key,
7 r_date ,
8 car_number
speed_pedal
10 break_pedal
11 steer_angle
12 direct_light
13 speed,
14 area_number
15 substring(r_date, 0, 8) as wrk_date
16 | from Smartcar_Drive_Info
17| where substring(r_date, 0, 8) '${working_day}';
9 )
)
)
9
그림 6.98 주제 영역 2의 운행 데이터 생성 하이브 쿼리
06. 내 문서의 workflow/hive_script/subject2에 세 번째 하이브 스크립트 파일을 만든다. subject2 디렉터리에서
[새 문서] -
→ [Hive 쿼리를 클릭한다.
07. 하이브 에디트 창이 활성화되면 하이브의 Managed 영역에 운행 데이터를 저장하기 위한 테이블 생성 스크립트
를 작성하고 저장한다. 파일 이름은 "create_table_managed_smartcar_drive_info.hql"로 지정한다. 아래 그림
6.99를 자세히 보면 “스마트카 마스터" 데이터와 스마트카 운전자의 운행” 데이터가 결합된 테이블로 생성하는 것
을 확인할 수 있다.
279
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
Hive ។ Add a na... Add a des...
Database default i o text ?
1 create table if not exists Managed_SmartCar_Drive_Info (
2 car_number string,
3 sex string,
4 age string,
5 marriage string,
6 region string,
7 job string,
8 car_capacity string,
9 car year string,
10 car_model string,
11
12 speed_pedal string,
13 break_pedal string,
14 steer_angle string,
15 direct_light string,
16 speed string,
17 area number string,
18 reg_date string
191)
20 partitioned by( biz_date string )
21 row format delimited
22 fields terminated by ','
23 stored as textfile;
1
그림 6.99 주제 영역 2의 Managed 테이블 생성 하이브 쿼리
08. 마지막으로 내 문서의 workflow/hive_script/subject2에 네 번째 하이브 스크립트 파일을 만든다. subject2 디
렉터리에서 [새 문서] → [Hive 쿼리를 클릭한다.
09. 하이브 에디트 창이 활성화되면 “스마트카 운전자 운행 데이터와 “스마트카 마스터” 데이터를 조인한 후, 삽입
하는 하이브 스크립트를 동적 파티션 설정과 함께 작성한다. 파일 이름을 "insert_table_managed_smartcar_
drive_info.hqi”? 927 taolch.
. set hive.exec.dynamic partition=true;
• set hive.exec.dynamic.partition.mode=nonstrict;
280
06 빅데이터 탐색
Hive Add a nam... Add a desc... 14
Database default 유형 textr ?
6
7
8
9
1 set hive.exec.dynamic. partition=true;
2 set hive.exec.dynamic.partition.mode=nonstrict;
3
4 insert overwrite table Managed_SmartCar_drive_Info partition(biz_date)
5 select
ti.car_number,
t1.sex,
t1.age,
t1.marriage,
10 ti.region,
11 ti.job,
12 ti.car_capacity,
13 ti.car year,
14 ti.car_model,
15 t2.speed_pedal,
16 t2.break_pedal,
17 t2.steer_angle,
18 t2.direct_light ,
19 t2.speed,
20 t2.area number |
21 t2.r_date,
22 substring(t2.r_date, 0, 8) as biz_date
23 from Smartcar_Master_over18 ti join SmartCar Drive Info 2 t2
24 on t1.car_number = t2.car_number and substring(t2.r_date, 0,8) = '${working_day}'; .....................
그림 6.100 주제 영역 2의 Managed 테이블에 데이터를 생성하는 하이브 쿼리
10. 이제 워크플로를 만든다. 휴 상단 쿼리 콤보박스 메뉴의 [스케줄러] → [Workflow를 선택해 워크플로를 작성한다.
11. 첫 번째 작업으로 워크플로 작성을 위한 우지 편집기가 나타나면 상단의 작업 툴 박스에서 “Hive 쿼리 작업을 선
택해 워크플로의 첫 번째 작업 노드에 드래그 앤드 드롭한다.
12. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 create _table_smartcar_drive_info_2hql을 선택한 후
[추가] 버튼을 클릭한다.
13. 두 번째 작업을 위해 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 선택해 워크플로의 두 번째 작업 노드에 드
래그 앤드 드롭한다.
14. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 insert_table_smartcar_drive_info_2hql을 선택한 후
[추가] 버튼을 클릭한다.
15. [매개변수를 누르고 working_day의 매개변수에 우지의 예약 스케줄러에서 정의할 ${today} 매개변수를 할당
한다.
working day=${today} u
1
281
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
16. 세 번째 마지막 작업을 위해 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 세 번째 작업 노드에 드
래그 앤드 드롭한다.
17. 사용할 Hive 스크립트 파일을 선택한다. creale_table_managed_smartcar_drive_info.hq을 선택한 후 [추가]
버튼을 클릭한다.
18. 네 번째 작업을 위해 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 네 번째 작업 노드에 드래그 앤
드 드롭한다.
19. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 insert_table_managed_smartcar_drive_info.hql을
선택한 후 [추가] 버튼을 클릭한다.
20. [매개변수를 누르고 working_day의 매개변수에 우지의 예약 스케줄러에서 정의할 ${today} 매개변수를 할당
한다.
working_day=${today}
21. 워크플로의 이름을 작성한다. 워크플로 상단의 “My Workflow"를 클릭하고 "Subject 2 - Workflow"로 변경한 후
[확인] 버튼을 클릭한다.
22. 워크플로 작성을 완료한다. 우측 상단의 [저장] 버튼을 누른다.
23. 이제 작성한 워크플로를 작동하기 위한 예약 작업을 생성한다. 쿼리 콤보박스 메뉴의 [스케줄러] → [예약을 선택
한다.
24. 먼저 예약 작업 이름을 입력한다. 상단의 [My Schedule]를 클릭하고 "Subject 2 - 예약" 으로 입력한다.
25. 예약 작업이 사용할 워크플로를 선택한다. “예정된 Workflow는 무엇입니까?" 라는 메시지의 하단에 있는
"Workflow 선택…”을 클릭해 앞서 만든 주제 영역 2의 워크플로인 "Subject 2 - Workflow"를 선택한다.
26. 예약 작업 워크플로를 실행하기 위한 스케줄 값을 입력한다.
실행 간격: 매일, 02시
시작 일자: 2020년 03월 23일, 00시 00분
종료 일자: 2020년 12월 31일, 23시 59분
MZICH: Asia/Seoul
27. 예약 작업에서 사용할 매개변수인 working_day 값을 예약 작업의 매개변수로 정의한다.
앞서 워크플로의 하이브 작업에서는 매개변수를 working_day=${today}"로 등록했다. working_day 값을 예약
작업의 내장 함수를 통해 설정한다.
${coord:formatTime(coord:dateTzoffset(coord:nominalTime(), "Asia/Seoul"), 'yyyyMMdd')}
.
.
.
282
06 빅데이터 탐색
28. 우지의 예약 작업 설정이 모두 끝났다. [저장] 버튼을 클릭해 작성을 완료한다.
29. 작성이 완료된 예약 작업을 우측 상단의 [제출] 버튼을 클릭해 실행한다. 참고로 이번 주제 영역 2의 워크플로는 처
리량이 많은 작업으로 필자의 파일럿 환경에서 약 10여 분 정도 실행됐다.
30. 제출된 예약 작업 상태를 확인해 본다. 좌측 드롭박스 메뉴에서 [Job] , [일정]을 선택한다. 앞서 등록한 "Subject
2 - 예약"이 "Running" 상태로, 매일 새벽 02시가 되면 등록된 워크플로(Subject 2 - Workflow)를 작동시키게
된다. 새벽 2시까지 기다릴 수 없으니 앞서 주제 영역 1에서 설명한 Workflow 즉시 실행해 보기"를 참고해 곧바
로 실행해 본다.
31. "Subject 2 - Workflow"가 정상적으로 작동됐는지 확인한다. 휴의 Hive Editor로 이동해서 그림 6.101과 같이 하
이브 QL을 작성해서 실행한다. “biz_date=20200322" 날짜는 독자들의 파일럿 환경의 실행 날짜와 맞춰야 한다.
Hive Add a nam... Add a des... L
Database default 유형 text 1
1 select * from managed_smartcar_status_info
2] where biz date = '20200322' limit 10
car_number sex age marriage region job car_capacity car_year car_model speed_pedal breakpedal steer_angle
1 A0027 여 53 기혼 경남 공무원 1700 2014 G 0 2 F
2 A0096 여 69 미혼 중남 학생 1200 2006 H 3 0 F
3 0007 남 66 미혼 전북 학생 3000 2002 D 4 0 E
4 B0034 남 51 미혼 경북 개인사업 1500 2015 E 1 0
5 B0050 여 70 미혼 전북 학생 1500 2009 D 0 0 F
그림 6.101 주제 영역 2 워크플로의 실행 결과 확인
주제 영역 2를 정리하자면 앞서 만든 워크플로는 매일 새벽 2시가 되면 HBase에 적재돼 있는 2020년 03월 22일
자의 “스마트카 운전자 운행 데이터를 모두 하이브의 테이블로 옮기는 작업을 선행하게 된다. 그런 다음 “스마트
카 마스터 데이터와 조인 작업으로 운전자 기본정보를 추가해서 확장된 “스마트카 운전자 운행기록 정보" 마트 데
이터를 최종적으로 만든다.
저사양 파일럿 환경: HBase 서비스를 정지한다.
- HBase 서비스: CM 홈 → [HBase] → [정지]
283
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
주제 영역 3. 이상 운전 패턴 스마트카 정보 워크플로 작성 실습
주제 영역 3의 워크플로는 2020년 03월 22일에 스마트카 운전자의 운행 기록을 분석해서 과속,
급제동, 급회전이 빈번한 차량들을 스코어링한 마트 데이터를 생성한다. 과속과 급제동의 경우, 당
일(22일)의 차량별로 가속 페달과 브레이크 페달의 평균값을 구하고, 관련 표준편차 값은 과거의
모든 데이터를 대상으로 산출해서 과속/급제동 표준값이 각각 “2” 이상인 차량의 경우만 “비정상
(abnormal)인 차량으로 판단했다. 급회전의 경우 당일(22일) 기준으로 Left/Right 회전각 “2-3"
단계를 “1000번 이상 했을 경우 급회전이 빈번한 “비정상(abnormal)” 차량으로 지정했다. 워크플
로의 하이브 작업에 사용되는 하이브 QL은 C://예제소스/bigdata2nd-master/CH06/HiveQL/
의 경로에서 제공되므로 필요 시 해당 파일을 열어 복사/붙여넣기 하면 된다.
01. 휴의 좌측 드롭박스 메뉴에서 [문서를 선택해 [내 문서]에 생성해 놓은 주제 영역 3의 작업 디렉터리로 이동한다.
41: /workflow/hive_script/subject3
02. 주제 영역 3에서는 사용할 하이브 스크립트 파일을 두 개 작성한다. 먼저 내 문서의 /workflow/hive_script/
subject3으로 이동해서 [새 문서] → [Hive 쿼리를 차례로 선택한다.
03. 하이브 에디트 창이 나타나고 운전자의 이상 운행 패턴을 관리하기 위한 하이브 테이블 스크립트를 작성하고 [제
장] 버튼을 클릭한다. 파일명은 "create_table_managed_smartcar_symptom_info.hal"로 지정한다.
Hive A create_tabl... Add a desc...
Database default 유형 textr 7 ?
1 create table if not exists Managed_SmartCar_Symptom_Info (
2 car_number string,
3 speed_p_avg string,
4 speed_p_symptom string,
5 break_p_avg string,
6 break_p_symptom string,
7 steer_a_cnt string,
8 steer_p_symptom string,
9 biz_date string
10)
11 row format delimited
12 | fields terminated by
13| stored as textfile;
14
:
그림 6.102 주제 영역 3의 Managed 테이블을 생성하는 하이브 쿼리
04. 계속해서 내 문서의 /workflow/hive_script/subject3 위치에 두 번째 하이브 스크립트 파일을 만들어 본다.
"subject3" 디렉터리에서 [새 문서] → [Hive 쿼리를 선택한다.
-
284
06 DICIEM
05. 하이브 에디트 창이 나타나고 운전자의 이상 운행 패턴을 Select/Insert하는 하이브 쿼리 스크립트를 작성하고 [제
HES 32/6/C). 202 "insert_table_managed_smartcar_symptom_info.ngi"? |Dich
Hive Add a nam... Add a des... R
1 insert into table Managed_SmartCar_Symptom_Info
select
t1.car_number,
t1.speed_p_avg_by_carnum,
case
t3.speed_p_avg) / t4.speed_p_std)) > 2
가속 페달
t3.break_p_avg) / t4.break_p_std)) > 2
when (abs((t1.speed_p_avg_by_carnum
then 'abnormal'
else 'normal'
end
as speed_P_symptom_score,
t1.break_p_avg_by_carnum,
case
when (abs((t1.break_P_avg_by_carnum
then abnormal
else 'normal'
end
as break_P_symptom_score,
t2.steer_a_count,
case
when (t2.steer_a_count) 2000
then 'abnormal'
else 'normal'
end
as steer_p_symptom_score,
t1.biz_date
브레이크 페달
>
from
운전대
(select car_number,
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
2526 27
28
29
30
31
32
33
34 join
35
36
37
38
39
40
41 on
42占
占
占88
biz_date,
avg(speed_pedal) as speed_p_avg_by_carnum,
avg(break_pedal) as break_p_avg_by_carnum
from managed_smartcar_drive_info
where biz_date = '${working day}'
group by car_number, biz_date) t1
(select car_number,
count(*) as steer_a_count
from managed_smartcar_drive_info
where steer_angle in ('L2', '13', 'R2','R3') and
biz_date= '${working day}
group by car_number) t2
t1.car_number = t2.car_number,
(select avg(speed_pedal) as speed_P_avg,
占
占
占
占
占
占44
45
46
47
48
49
avg(break_pedal) as break_p_avg
from managed_smartcar_drive_info ) t3,
(select stddev_pop(s.speed_P_avg_by_carnum) as speed_p_std, stddev_pop(s.break_P_avg_by_carnum) as break_p_std
from (select car_number,
avg(speed_pedal) as speed_p_avg_by_carnum,
avg(break_pedal) as break_P_avg_by_carnum
from managed_smartcar_drive_info
group by car_number) s) t4
그림 6.103 주제 영역 3의 Managed 테이블에 데이터를 생성하는 하이브 쿼리
50
51
52
그림 6.103의 하이브 쿼리는 한 번의 실행으로 “스마트카 운전자 운행 정보(Managed_SmartCar_Drive_Info)"로
부터 차량 번호별 스피드 페달, 운전대, 브레이크 페달의 데이터 분석 결과를 Managed_SmartCar_Symptom_
Info 테이블에 저장한다. 쿼리를 자세히 살펴보면 전체 평균과 표준편차 값을 구하고, 당일(2020년 03월 22일)
에 차량별 편차를 구해 이상 차량임을 판단하고 있는데, 이러한 처리 과정을 데이터의 피처 엔지니어링(Feature
285
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
Engineering)이라고 하며, 기존의 변수를 가공해 새로운 변수와 정보를 추가하는 과정에 해당한다. 참고로 해당
쿼리가 실행될 때 Job Browser를 모니터링해 보면 7개의 잡과 10여 개 이상의 맵리듀스가 실행되는 것을 확인할
수 있다. 총 수행 시간도 필자의 파일럿 환경에서 10여 분 정도 소요되는 다소 무거운 하이브 쿼리다.
Tip _ 빅데이터 분석을 위한 탐색 및 전처리 작업
일반적으로 빅데이터 인사이트는 탐색 단계에서 80% 이상이 발견되고, 나머지 20%는 분석 단계에서 검증하며 얻
게 된다. 특히 탐색 단계에서는 데이터의 전처리 작업의 비중이 매우 높은데 일련의 과정들을 그림 6.104로 정의할
수 있다. 크게 4개의 단계가 있으며, 사용하는 분석 기법과 알고리즘, 분석 환경에 맞게 선택적으로 수행하게 된다.
파일럿 프로젝트에서는 그림 6.104의 모든 전처리 작업을 다루지는 않는다. 빅데이터 모델러, 데이터 엔지니어, 분
석가에 관심 있는 독자라면 향후 이 분야의 이론과 기술들을 좀 더 집중적으로 공부해 보길 바란다.
데이터셋 확인 결측값 처리 이상값 처리 피처 엔지니어링
/삭제
✔ 대체
✔ 변수화
4 변수 필드 확인 ✔ 삭제
- 독립 종속 변수의 정의 - 전체 삭제, 부분 삭제
- 변수의 유형(범주/연속형) ✔ 대체
- 변수의 데이터 타입 - 평균, 최빈값, 중앙값 등
/ Raw 데이터 확인 ✔ 예측값
- 단변수: 히스토그램, 박스플롯 - 정상 데이터로 예측값 생성
평균, 최빈 중앙, 분포, 최대/최소
이변수: 스캐터 플롯, 막대차트
연속형 연속형: 상관 분석
. 범주형범주형 : 카이제곱 분석
범주형 연속형: T-Test/ANOVA
- 다변수
SCALING
- 변숫값 변환
BINNING
- 연속형 → 범주형
TRANSFORM
주변 변수를 활용해 재구성
DUMMY
- 범주형 → 연속형
/ 리모델
분리 처리
그림 6.104 빅데이터 분석을 위한 탐색 및 전처리 작업
06. 이제 워크플로를 만든다. 휴 상단의 쿼리 콤보박스의 [스케줄러] → [Workflow]를 선택해 우지 편집기로 이동한다.
07. 첫 번째 작업으로 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 첫 번째 작업 노드에 드래그 앤드
드롭한다.
08. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 내 문서의 /workflow/hive_script/subject3에 만들어 둔
create_table_managed_ smartcar_symptom_info.hql을 선택한 후 [추가] 버튼을 클릭한다.
09. 두 번째 작업을 위해 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 두 번째 작업 노드에 드래그 앤
드 드롭한다.
10. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 workflow/hive_script/subject3에 insert
table_managed_smartcar_symptom_info.hql을 선택한 후 [추가] 버튼을 클릭한다.
286
06 비데이터 탐색 287
11. [매개변수를 누르고 working_day의 매개변수에 우지의 예약 스케줄러에서 정의할 ${today}" 매개변수를 할당
한다.
• working day=${today}
12. 워크플로의 이름을 작성한다. 워크플로 상단의 [My Workflow]를 클릭하고, "Subject 3 - Workflow"로 변경한 후
[확인] 버튼을 누른다.
13. 워크플로 작성을 완료한다. 우측 상단의 [저장] 버튼을 누른다.
14. 이제 작성한 워크플로를 작동하기 위한 예약 작업을 생성한다. 상단의 쿼리 콤보박스에서 [스케줄러] → [예약을
차례로 선택한다.
15. 먼저 예약 작업 이름을 입력한다. 상단의 [My Scheduler]를 클릭하고 "Subject 3 - 예약”으로 입력한다.
16. 예약 작업이 사용할 워크플로를 선택한다. “예정된 Workflow는 무엇입니까?" 라는 메시지 하단에 있는 “Workflow
선택…"을 클릭해 앞서 만든 주제 영역 3의 워크플로인 "Subject 3 - Workflow"를 선택한다.
17. 예약 작업 워크플로를 실행시키기 위한 스케줄 값을 입력한다.
. 실행 간격: 매일, 03시
시작 일자: 2020년 03월 23일, 00시 00분
종료 일자: 2020년 12월 31일, 23시 59분
1|ZICH: Asia/Seoul
18. 워크플로에서 사용할 매개변수인 today 값을 예약 작업의 매개변수로 정의한다.
앞서 워크플로의 하이브 작업에서는 매개변수를 "working_day=${today}"로 등록했다. today의 값을
Coordinator의 내장 함수를 통해 설정한다.
${coord:formatTime(coord:dateTzoffset(coord:nominalTime(), "Asia/Seoul"), 'yyyyMMdd')}
19. 우지의 예약 작업 설정이 모두 끝났다. [저장] 버튼을 클릭해 작성을 완료한다.
20. 작성이 완료된 예약 작업을 우측 상단의 [제출] 버튼을 클릭해 실행한다.
21. 제출된 예약 작업 상태를 확인해 본다. 좌측 상단의 드롭박스 메뉴에서 [Job] → [일정]을 차례로 선택한다. 앞서 등
록한 "Subject 3 - 예약”이 “Running" 상태로, 매일 새벽 03시가 되면 등록된 워크플로를 작동시키게 된다. 새벽
3시까지 기다릴 수 없으니 앞서 주제 영역 1에서 설명한 “워크플로 즉시 실행해 보기"를 참고해 곧바로 실행해
본다.
22. "Subject 3 - Workflow"가 정상적으로 작동했는지 확인한다. 상단의 쿼리 콤보박스에서 [편집기] → [Hive]를 전
택해 하이브 에디터에서 그림 6.105와 같이 하이브 조회 쿼리를 작성해 실행한다. 참고로 "biz_date=20200322"
의 날짜는 독자들의 파일럿 환경의 biz_date 날짜로 맞춰야 한다.
| 실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
1
Hive insert_table_m... Add a descripti... 3
1m, 8s Database default 유형 textr 07
SELECT
car_number,
cast(speed_p_ave as int),
speed_p_symptom,
cast(break_P_avg as float),
break_p_symptom,
cast(steer_a_cnt as int),
steer_p_symptom,
9 biz_date
10 | FROM managed_smartcar_symptom_info
11| where biz_date = '20200322'
8
리 기록 저장된 리 결과 (94)
car_number Speedup.avg spoed_p_symptom breakp.avg break_p.symptom steer_a_cnt stear_p_symptom
A0004 1 normal 0.30251548 normal 1559 normal
2 A0097 normal 0.3166468 normal 156e normal
3 B0006 normal 0.30939576 normal 1552 normal
4 B0043 1 normal 0.30955213 normal 1558 normal
S B0051 1 normal 0.3005024 normal 1544 normal
6 B0065 1 normal 0.28641355 normal 1449 normal
7 90070 2 abnormal 0.20799153 abnormal 2959 abnormal
그림 6.105 주제 영역 3 워크플로의 실행 결과 확인
23. "비정상 스마트카 운행, 데이터를 차트로 재구성해 보면 좀 더 직관적으로 데이터를 탐색할 수 있다. 먼저 그림
6.106의 하이브 쿼리 실행 결과에서 [차트] 버튼을 선택한다.
쿼리 기록 저장된 쿼리 결과 (94)
유형
Bars
X축
<
car_number
Y축
speed_p_avg
break_p_avg
O steer_a_cnt
그룹
Choose a column to pivot...
제한
Limit the number of results to...
정렬
그림 6.106 주제 영역 3 워크플로의 실행 결과 확인 - 차트 선택
288
6 빅데이터 탐색
차트의 종류로 "Bars(막대)”를 선택한다. 첫 번째로 가속 페달의 비정상 패턴 차량을 조회해서 과속/난폭 운전 가능
성이 예상되는 차량들을 찾아보자.
이를 위해 X축에서는 "car_number"를 선택하고, Y축에서는 “speed_p_avg"를 선택한다.
2
15
0.5
0
그림 6.107 주제 영역 3 워크플로의 실행 결과 확인 - 차트 보기 1
조회 결과를 보면 차량별 가속 페달의 편차가 매우 높은 스마트카 차량 10대가 발견됐다.
두 번째로 브레이크 페달에서 비정상 패턴을 보이는 차량을 조회해서 급정지/난폭 운전의 가능성이 예상되는 차량
들을 찾아보자.
이를 위해 X축에서는 “car_number"를 유지하고, Y축에서는 "speed p_avg" 선택을 해제하고 “break_p_avg"
를 선택한다.
0.331406
0.31
025
0.2
0.15
0.1
0.05
그림 6.108 주제 영역 3 워크플로의 실행 결과 확인 - 차트 보기 2
조회 결과를 보면 차량별 브레이크 페달의 편차가 지나치게 낮은 스마트카 차량 10대가 발견됐다.
세 번째로 운전대의 비정상 패턴을 보이는 차량을 조회해서 급회전/난폭 운전의 가능성이 예상되는 차량들을 찾아
보자.
이를 위해 X축에서는 “car_number"를 유지하고, Y축에서는 "break_p_avg" 선택을 해제하고 "steer acnt"를 선택
한다.
289
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
2.346k ◎
2k
15
1k
500
그림 6.109 주제 영역 3 워크플로의 실행 결과 확인 - 차트 보기 3
조회된 결과를 보면 차량별 운전대 회전각이 평균보다 지나치게 높은 스마트카 차량 10대가 발견됐다.
위 3개의 차트를 분석해 보면 이상 운행 패턴을 보이는 운전자는 가속 페달, 브레이크 페달, 운전대 사용 패턴도 모
두 비정상인 것으로 파악됐다. 결국 3개의 변수(가속 페달, 브레이크 페달, 운전대)들은 서로 연관성이 매우 높다는
사실을 알 수 있다.
주제 영역 3에서는 하이브의 단순 기술적 통계량으로 이상 징후 차량들을 탐색했다. 여기서 스코어링된 차량 중 특
정값에 비정상 판정을 받은 차량의 경우 속도, 브레이크, 회전에 있어서도 다른 차량보다 수치가 지나치게 크거나/
낮게 나타난다는 것을 확인했다. 하이브를 잘 이용하면 빅데이터에 적재돼 있는 대용량 데이터도 쉽고 빠르게 탐색
적 분석을 할 수 있다.
주제 영역 4. 긴급 점검이 필요한 스마트카 정보 워크플로 작성
휴 내 문서: /workflow/hive_script/subject4
실습 2010
11
주제 영역 4의 워크플로는 2020년 03월 22일 스마트카의 다양한 센서로부터 수집된 데이터(타이
어, 라이트, 브레이크, 엔진, 배터리)를 분석해 긴급 점검이 필요한 스마트카 차량 리스트를 찾아내
는 것이다. 이번 하이브 쿼리 역시, 파일럿 프로젝트에서 실행하기에는 다소 무겁고 시간이 많이 소
요되는 맵리듀스 잡들을 만들어낸다. 하지만 이번 작업을 통해 “긴급 점검 차량 마트 데이터를 만
들면 이후부터는 단순 쿼리로 빠르게 긴급 점검 차량들을 조회해 볼 수 있게 된다. 워크플로의 하이
브 작업에 사용되는 하이브 QL은 C://예제소스/bigdata2nd-master/CH06/HiveQL/에서 확인
할 수 있으므로 필요 시 해당 파일을 열어서 복사한 후 붙여넣는 식으로 활용한다.
01. 휴의 좌측 드롭박스 메뉴에서 [문서를 선택해 [내 문서에 생성해 놓은 주제 영역 4의 작업 디렉터리로 이동한다.
290
CB 데이터 탐색
02. 주제 영역 4에서는 하이브 스크립트 파일 2개를 작성한다. 먼저 내 문서의 /workflow/hive_script/subject4로 이
동한 후 [새 문서] → [Hive 쿼리를 선택한다.
03. 하이브 에디터가 나타나면 스마트카 장비의 상태를 관리하기 위한 테이블 생성 스크립트를 작성하고 저장한다. 파
일 이름은 creale_table_managed_smartcar_emergency_check_info.hql로 입력한다.
Hive Add a name... Add a description...
Database default 유형 text
1 create table if not exists Managed_SmartCar Emergency_check_Info (
2 car_number string,
3| tire_check string,
4 light_check string,
5 engine_check string,
6| break_check string,
기 battery_check string,
8 biz_date string
9)
10 row format delimited
11 fields terminated by ,'
12 stored as textfile;
그림 6.110 주제 영역 4의 Managed 테이블을 생성하는 하이브 쿼리
04. 계속해서 내 문서의 workflow/hive_script/subject4에 두 번째 하이브 스크립트 파일을 만든다. subject4" 디렉
터리에서 [새 문서 → [Hive 쿼리를 선택한다. -
05. 하이브 에디트 창이 나타나면 긴급 점검이 필요한 스마트카를 Select/Insert하는 쿼리를 그림 6.111처럼 작성한 후
저장한다. 파일 이름은 insert_table_managed_smartcar_emergency_check_info.hql로 입력한다.
그림 6.111의 하이브 쿼리를 실행하면 스마트카의 6가지 점검 상태를 분석해서 그 결과를 “스마트카 간급 점검 차
량 정보(Managed_SmartCar_Emergency_Check_Info)” 마트 테이블에 저장한다. 쿼리의 내용을 자세히 살
펴보면, 주요 필드들을 가공해 스마트카 상태 점검을 위한 새로운 변수를 만들어 내는 피처 엔지니어링(Feature
Engineering) 쿼리로 구성돼 있다. 또한 RDBMS에서 자주 사용하는 Left Outer 조인 쿼리가 사용되는 것을 확인할
수 있다. 참고로 해당 하이브 QL은 대용량 쿼리로서, 실행 중에 8개 이상의 맵리듀스 잡과 태스크가 만들어지고 총
실행 시간은 10여 분 정도 된다.
291
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
Hive Add a nam... Add a des...
insert into table Managed SmartCar_Emergency_Check_Info
select
t1.car_number,
t2. symptom as tire_symptom,
t3.symptom as light_symptom,
t4.symptom as engine_symptom,
t5. symptom as break_symptom,
9 t6. symptom as battery_symptom 10 ti.biz_date
11 from
12 (select distinct car_number as car_number, biz_date
13 from managed_smartcar_status_info where biz_date - '${working day}') t1
14
15 left outer join ( select 타이어 점검
16 car_number,
17 avg(tire_fl) as tire_fl_avg) 18 avg(tire_fr) as tire_fr_avg,
19 avg(tire_b1) as tire_bl_avg
20 avg(tire_br) as tire_br_avg,
21 'Tire Check' as symptom
22 from managed_smartcar_status_info where biz_date = '${working day}' 23 group by car_number
24 having tire_fl_avg < 80
25 or tire_fr_avg < 80
26 or tire_bl_avg < 80
27 or tire_br_avg < 80 ) t2
28 on ti.car_number = t2.car_number
29
30 left outer join(select 라이트 점검
31 distinct car_number,
32 'Light Check' as symptom
33 from managed_smartcar_status_info
34 where biz_date = '${working day}' and (light_fl = '2'
35 or light_fr = '2'
36 or light_bl = 2'
37 or light_br = '2') t3
38 on ti.car_number = t3.car_number
39
40 left outer join ( select 엔진 점검
41 distinct car_number,
42 'Engine Check' as symptom
43 from managed_smartcar_status_info
44 where biz_date = '${working day}' and engine = 'C' ) t4
45 on t1.car_number = t4.car_number
46
47 left outer join ( select 브레이크 점검
48 distinct car_number,
49 Brake Check' as symptom 50 from managed_smartcar_status_info
51 where biz_date= '${working_day}' and break = 'C' ) t5
52
53 on t1.car number - t5.car_number
54
55 left outer join ( select 베터리 점검
56 car_number,
57 avg(battery) as battery_avg,
58 Battery Check' as symptom
where biz_date ${working day)
60 group by car_number having battery_avg < 30 ) t6
59 from managed_smartcar_status_info
61 on t1.car_number = t6.car_number
62
63 where t2.symptom is not null or t3.symptom is not null
64 or t4.symptom is not null
65 or t5.symptom is not null
66 or t6. symptom is not null
그림 6.111 주제 영역 4의 Managed 테이블에 데이터를 생성하는 하이브 쿼리
292
06 비데이터 탐사
Q. 이제 워크플로를 만든다. 휴의 상단 쿼리 콤보박스에서 [스케줄 [Workflow]를 선택해서 우지 편집기를 실
행한다.
07. 첫 번째 작업으로 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 첫 번째 작업 노드에 드래그 앤드
드롭한다.
08. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 /workflow/hive_script/subjectal create
table_smartcar_emergency_check_info.hql을 선택한 후 [추가] 버튼을 클릭한다.
09. 두 번째 작업을 위해 워크플로의 작업 툴박스에서 Hive 쿼리 작업을 워크플로의 두 번째 작업 노드에 드래그 앤
드 드롭한다.
10. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 /workflow/hive_script/subject4에 insert_
table_managed_smartcar_emergency_check_info.hql을 선택한 후 [추가] 버튼을 클릭한다.
11. [매개변수를 누르고 working_day의 매개변수에 우지의 예약 스케줄러에서 정의할 ${today} 매개변수를 할당
한다.
working day=${today} 1
12 워크플로의 이름을 작성한다. 워크플로 상단의 [My Workflow]를 클릭하고, "Subject 4 - Workflow"로 변경한 후
[확인] 버튼을 클릭한다.
13. Workflow 작성을 완료 한다. 우측 상단의 [저장] 버튼을 클릭한다.
14. 이제 작성한 워크플로를 작동하기 위한 예약 작업을 생성한다. 상단의 쿼리 콤보박스에서 [스케줄러] →→ [예약] 메
뉴를 선택한다.
15. 먼저 예약 작업 이름을 입력한다. 상단의 [My Scheduler]를 클릭하고 "Subject 4 - 예약”으로 입력한다.
16. 예약 작업이 사용할 워크플로를 선택한다. “예정된 Workflow는 무엇입니까?"라는 메시지 하단에 있는
Workflow 선택…"을 클릭해 앞서 만든 주제 영역 4의 워크플로인 "Subject 4 - Workflow"를 선택한다.
17. 예약 작업이 워크플로를 실행하기 위한 스케줄 값을 입력한다.
. 실행 간격: 매일, 04시
시작 일자: 2020년 03월 23일, 00시 00분
. 종료 일자: 2020년 12월 31일, 23시 59분
1
MIZICH: Asia/Seoul
293
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
18. 워크플로에서 사용할 매개변수인 today 값을 예약 작업의 매개변수로 정의한다.
앞서 워크플로의 하이브 작업에서는 매개변수를 "working_day=$(today}"로 등록했다. today의 값을 예약 작업
의 내장 함수를 통해 설정한다.
${coord: formatTime(coord:dateTzoffset(coord:nominalTime(), "Asia/Seoul"), 'yyyyMMdd')}
19. 우지의 예약 작업 설정이 모두 끝났다. [저장] 버튼을 클릭해 작성을 완료한다.
20. 작성이 완료된 예약 작업을 우측 상단의 [제출] 버튼을 클릭해 실행한다.
21. 제출된 예약 작업 상태를 확인해 보자. 좌측 상단의 드롭박스 메뉴를 클릭해 [Job] → [일정]을 차례로 선택한다. 앞
서 등록한 "Subject 4 - 예약"이 "Running" 상태로, 매일 새벽 04시가 되면 등록된 워크플로를 작동시키게 된다.
새벽 4시까지 기다릴 수 없으니 앞서 주제 영역 1에서 소개한 “워크플로 즉시 실행해 보기"를 참고해 곧바로 실행
-
해 본다.
22. "Subject 4 - Workflow"가 정상적으로 작동했는지 확인한다. 휴의 Hive Editor로 이동해서 그림 6.112와 같이 하
이브 QL을 작성해서 실행한다. "2020년 03월 22일 긴급 점검이 필요한 스마트카 차량”의 정보가 조회될 것이다.
필자의 경우 33대의 차량에 대해 긴급 점검 대상으로 조회됐다. "biz_date=20220322" 의 날짜는 독자들의 파일럿
환경의 날짜로 맞춰야 한다.
Hive Add a name... Add a description...
1 select * from managed_smartcar_emergency_check_info
2 | where biz_date = '20200322'
쿼리 기록 저장된 쿼리 2 결과 (35)
car_number tire_check light_check engine_check break_check battery_check
1 A0090 NULL NULL Engine Check NULL NULL
2 C0078 Tire Check NULL NULL NULL NULL
3 E0001 NULL NULL Engine Check NULL NULL
4 H0049 Tire Check NULL NULL NULL NULL
5 H0094 Tire Check NULL NULL NULL NULL
그림 6.112 주제 영역 4 워크플로의 실행 결과 확인
주제 영역 4에서는 긴급 점검이 필요한 스마트카 정보를 찾아봤다. 이때 긴급 점검 대상 차량을 판
단하기 위해 기준값들이 사용되며, 과거 운행 데이터로부터 탐색적 분석을 진행해 관련 지표를 정의
한다. 지표의 신뢰도를 높이기 위해 대규모 데이터를 확보하고, 관련 업무 전문가로부터 영향력 있
는 변수를 도출하는 작업도 진행된다.
:
294
(6 빅데이터 탐색
주제 영역 5. 스마트카 운전자 차량용품 구매 이력 정보 워크플로 작성 L. 10000 실습
이번 주제 영역 5의 워크플로는 2020년 03월 스마트카 운전자들이 구매한 “스마트카 차량용품 구
매 이력”과 “스마트카 마스터 데이터를 결합한 데이터셋을 만들고, 차량번호별 구매한 상품 리스
트를 로컬 파일시템에 생성하는 것이다. 스마트카 차량용품 구매 이력 데이터는 SmartCar Item.
Bus List 테이블로 구성돼 있고, 스마트카 마스터 데이터는 앞서 여러 번 사용했던 SmartCar
Master Over18 테이블을 이용할 것이다. 워크플로의 하이브 작업에 사용되는 하이브 QL은 C://
예제소스/bigdata2nd-master/CHO6/HiveQL/에서 제공되므로 필요 시 해당 파일을 열어 복사
및 붙여넣기 방식으로 이용한다.
01. 휴의 좌측 드롭박스 메뉴에서 [문서를 선택해 [내 문서에 생성해 놓은 주제 영역 5의 작업 디렉터리로 이동한다.
휴 내 문서: /workflow/hive_script/subject5
02. 주제 영역 5에서는 하이브 스크립트 파일을 두 개 작성한다. 먼저 내 문서의 /workflow/hive_script/subject5 위
치로 이동해서 [새 문서] → [Hive 쿼리를 선택한다.
03. 하이브 에디터가 나타나면 구매 이력을 관리하기 위한 하이브 테이블 생성 스크립트를 그림 6.113처럼 작성하고
저장한다. 파일 이름은 create_table_smartcar_item_buylist_info.hql로 입력한다.
Hive Add a name... Add a descr...
?
6
Database defaultr 유형 text r
11| create table if not exists Managed_SmartCar_Item_BuyList_Info (
2 car_number string,
3 sex string,
4 age string,
5| marriage string,
region string,
7 job string,
8 car_capacity string,
9 car year string,
10 car_model string,
11 item string)
12 score string
13)
14| partitioned by( biz_month string )
15 | row format delimited
16| fields terminated by ','
17 stored as textfile;
그림 6.113 주제 영역 5의 Managed 테이블을 생성하는 하이브 쿼리
295
실무 프로젝트로 배우는 빅데이터 기술 데이터 수집, 적재, 처리, 분석, 머신러닝까지
04. 계속해서 내 문서의 workllow/hive_script/subjects의 위치에 두 번째 하이브 스크립트 파일을 만들어 본다.
subject5 디렉터리에서 [새 문서] → [Hive 쿼리를 선택한다.
05. 하이브 에디트 창이 나타나면 동적 파티션을 설정하고 “차량 물품 구매리스트”와 “스마트카 마스터” 데이터를 조인
하는 하이브 스크립트를 작성하고 저장한다. 파일 이름은 insert_table_managed_smartcar_item_buylist_info.
hgl로 입력한다.
- set hive.exec.dynamic.partition=true;
▪ set hive.exec.dynamic.partition.mode=nonstrict;
Hive Add a name... Add a description... :
Database default 유형 text v ?
1 set hive.exec.dynamic.partition=true;
2 set hive.exec.dynamic.partition.mode=nonstrict;
3
4 insert overwrite table Managed_SmartCar_Item_BuyList_Info partition (biz_month)
5 select
6 t1.car_number,
7 t1.sex,
8 t1.age,
t1.marriage,
10 t1.region,
11 t1.job,
12 t1.car_capacity,
13 t1.car year,
14 ti.car_model,
15 t2.item,
16 t2.score,
17 t2.month as biz_month
18 from
19 SmartCar_Master_Over18 ti join SmartCar_Item_Buylist t2
201on
21 t1.car_number t2.car_number
22] where
23 t2.month = '202003 '
그림 6.114 주제 영역 5의 Managed 테이블에 데이터를 생성하는 하이브 쿼리
이번 주제 영역 5의 동적 파티션은 월(Month) 단위다. 앞의 주제 영역 1~4는 일(Day) 단위였다. 그림 6.114의 하이
브 QL의 마지막 줄을 보면 “2020년 03월"에 해당하는 물품 구매 데이터를 가져오는 것을 확인할 수 있다.
06. 내 문서의 /workflow/hive_script/subject5에 세 번째 하이브 스크립트 파일을 만들어 본다. subjects 디렉터리
에서 [새 문서] → [Hive 쿼리를 선택한다.
07. 하이브 에디트 창이 나타나면 구매한 상품 리스트를 조회해서 로컬 파일시스템의 특정 위치인 "/home/
pilot-pit/item-buy-list"에 파일을 생성하는 하이브 스크립트를 작성하고 저장한다. 파일 이름은 local_
save_managed_smartcar_item_buylist_info.hale getch.
296
06 빅데이터 탐색
Hive Add a name... Add a description...
Database default - 유형 text 한?
1 insert overwrite local directory '/home/pilot-pit/item buy list!
2 ROW FORMAT DELIMITED
3 FIELDS TERMINATED BY ,'
4 select car_number, concat_ws(",", collect_set(item))
5 from managed_smartcar_item_buylist_info
6 group by car_number
그림 6.115 주제 영역 5의 차량별 상품 구매 리스트 결과 파일 생성
그림 6.115의 하이브 QL은 SELECT 쿼리를 실행한 결과를 로컬 디렉터리인 /home/pilot-pit/item-buy Hist에 생
성하는 하이브 쿼리다. SELECT 구문을 보면 collect_set) 함수를 이용해 차량번호별로 그루핑한 결과를 하나의
상품 리스트로 구성한다.
08. 이제 워크플로를 만든다. 휴의 상단 쿼리 콤보박스에서 [스케줄러] → [WorkFlow]를 선택해 우지 편집기를 실행
한다.
09. 첫 번째 작업으로 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 첫 번째 작업 노드에 드래그 앤드
드롭한다.
10. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 만든 내 문서의 workflow/hive_script/subjects에 create_
table_managed_smartcar_item_buylist_info.hg을 선택한 후 [추가] 버튼을 클릭한다.
11. 두 번째 작업을 위해 워크플로의 작업 툴박스에서 “Hive 쿼리 작업을 워크플로의 두 번째 작업 노드에 드래그 앤
드 드롭한다.
12. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 내 문서의 /workflow/hive_script/subject5 위치에 만들었
던 insert_table_managed_smartcar_item_buylist_info.hgl을 선택한 후 [추가] 버튼을 누른다.
13. 세번째 작업을 위해 Workflow의 작업 툴박스에서 "Hive 쿼리 작업을 Workflow의 세 번째 작업 노드에 드래그 앤
드 드롭한다.
14. 사용할 Hive 스크립트 파일을 선택한다. 앞 단계에서 내 문서의 /workflow/hive_script/subject5 위치에 만들었
던 local_save_managed_smartcar_item_buylist_info.hql을 선택한 후 [추가] 버튼을 누른다.
15. 워크플로의 이름을 작성한다. 워크플로 상단의 [My Workflow]를 클릭하고, "Subject 5 - Workflow"로 변경한 후
[확인] 버튼을 클릭한다.
16. 워크플로 작성을 완료한다. 우측 상단의 [저장] 버튼을 누른다.
297
실무 프로젝트로 배우는 빅데이터 기술: 데이터 수집, 적재, 처리, 분석, 머신러닝까지
17. 이제 작성한 워크플로를 작동시키기 위한 예약 작업을 생성한다. 상단의 쿼리 콤보박스에서 [스케줄러] → [예약]을
선택한다.
18. 먼저 예약 작업의 이름을 입력한다. 상단의 [My Scheduler]를 클릭하고 "Subject 5 - 예약"으로 입력한다.
19. 예약 작업이 사용할 워크플로를 선택한다. “예정된 Workflow는 무엇입니까?"라는 메시지 하단에 있는
"Workflow 선택…"을 클릭해 앞서 만든 주제 영역 5의 워크플로 "Subject 5 - Workflow"를 선택한다.
20. 예약 작업이 워크플로를 실행시키기 위한 스케줄 값을 입력한다.
. 실행 간격: 매일, 05시
시작 일자: 2020년 03월 23일, 00시 00분
종료 일자: 2020년 12월 31일, 23시 59분
MIZECH: Asia/Seoul
21. 우지의 예약 작업 설정이 모두 끝났다. [저장] 버튼을 누르고 작성을 완료한다.
22. 작성이 완료된 예약 작업을 우측 상단의 [제출] 버튼을 클릭해 실행한다.
23. 제출된 예약 작업 상태를 확인해 본다. 좌측 상단의 드롭박스 메뉴를 클릭해 [Job] → [일정]을 차례로 선택한다. 앞
서 등록한 "Subject 5 - 예약"이 "Running" 상태로, 매일 새벽 05시가 되면 등록된 워크플로를 작동시키게 된다.
새벽 5시까지 기다릴 수 없으니 앞서 주제 영역 1에서 소개한 워크플로 즉시 실행해 보기"를 참고해 곧바로 실행
해 본다.
24. "Subject 5 - Workflow"가 정상적으로 작동했는지 확인한다. 상단 쿼리 콤보박스에서 [편집기] → [Hive]를 선택
해 하이브 에디터 창에 그림 6.116과 같이 하이브 QL을 "biz_month=202003" 조건으로 작성해서 실행한다.
Hive insert_t... Add a d... 1
0.888 Database default 유형 textv ?
1/ select * from managed_smartcar_item_buylist_info 2
3 where biz_month = '202003'|
키리 기 서당 리 결과 (100 +)
managed_smartcar jtom_buylist_info.car_number managed_smartcar_item_buylist_info.sex managed_smartcar_item_buylist_info.age managed_smartcar.
1 20035 남 65 기혼
2 10090 남 40 기혼
5 3 K0095 여 48 미론
4 Y0042 남 66 기혼
5 W0023 44 미은
그림 6.116 주제 영역 5 워크플로의 실행 결과 확인 1
.
298
06 데이터 시
차량 번호별로 용품을 구매한 리스트 파일이 Server02의 로컬 파일 시스템에 생성됐는지 확인한다. Server020에
PuTTY로 SSH 접속한 후 다음 명령을 실행한다.
$ more /home/pilot-pjt/item-buy-list/000000_0
Iter, item-010. icen-004, iter-019, item-020, Item-014. Item-009, Iterni-025, Item-016, Item-015. icer-029, IEEt-00 Seems. TEC-007, item-02icen028, Item-017. Iteri-022. Icert-02 6, iter.- 029, icert - 027. Iter-001, Ice - 025, CA-005,
E. Item-012)
te. Item-012 , Iten-005, Item-006, Item-007. Itern-015. Iteri-014. Item-027, Item-025, Item-028,In-item-00 ne, item-016. item-020, item -030, Item-021, item-009, item-02 2, item-017. Icern-026, Itert-024
s, teer-029, icen-030, item-010, iter-016, Item-026, Item-006, item-01e, itert-02 3, cem-012, cem-021, iter-20
ther-020, Ttern-01 1, item-016, item-024, iteri-019, Item-025, Icer-002, iter-023
22, Tter-022, iter-008. Itemi- 022. Itemi-003, Itemi-017. Item-011, Iter-002 , Itern - 020,Item-024, iter-02 3. SEEI-01
ce, iter-002, item-023, itern-015. Item-019. Itern-009Item-005
leen-one, iter-01 , item-009, Icem-014, Item-025, Item-026, Item-020, item-020, Icert-029, item-013.10 TEEN-00 22, item-008, item-001. Item-022, Icem-017. Item-028, Item-005. Item-025, Itert-026. Item-025, Iter-018. Iter-006 1
-006 , item-050, Icem-022 , item-02 1, itera-02 2, Item-005, Item-026, Icern-019, Itert-029, Item-009, item-025, item-00 2. Ster 021. Ice-002, item-003. Itemi- 027, Item-02 4, Item-018, Item-017. Item - 020, Iteri-012. Item-008
102, Icem-028, item-016. Itemi- 030, Item-022, Item-004, iten-019, Itemi-005, Item-01 4item-013. icer-023. Item-00
cen-007, item-003, iterr-015, Item-012. Item-013. Item-027, Iter - 017, Item - 024, Item-011, Ttem-006
item - 026, Item-010 item-012, Itern-002 ,Item-001, Item-025, Item-009, iter-004, item-020 , cen-00s, item-01
1-021, Item-019. Iter-006, Itemi- 0 13, Item-022, Item-024, Item-005, item-002, ice-01e. Item-015, Item-021 -228, Icem-022, iter-01e, item-021, Item-014, Item-002, Item-027, Iter-019, item-026. iter-004, cer-02
item-005. Item-006. Item-009. Itern-005, Item-024, iter-016. Eter-011. Item-006
그림 6.117 주제 영역 5 워크플로의 실행 결과 확인 2
그림 6.117을 보면 차량 번호별로 그루핑된 상품 구매 리스트를 볼 수 있다. 7장에서는 이 구매 리스트 정보를 분석
해서 상품 추천 모델을 만들게 된다